

## Finding: for tasks that are aligned with surface similarity, performance is high across the board
e.g. Haikus based on literal imagery

## For unconventional tasks
 Clear performance hierarchy: LM judge > embeddings > BM25

## Finding: for ad hoc methods, performance is highly variable across tasks...


### Finding: query expansion is powerful but uses inconsistent nomenclature

The point is to do queries that VecEOL cannot
## Finding: for criteria with a intuitive + effective taxonomy, the representation problem becomes trivial given more LM compute







### Finding: "in-one-word" methods are a strong baseline
- tldr; in-one-word methods are highly performant for documents and criteria where it's possible to extract the criteria in one forward pass and to express it in one word

For simple tasks, zero-shot in-one-word methods can provide very strong performance (CITE). They have also provided a strong starting point for finetuning, particularly for VLMs.
Because of this, it's not surprising that they are a strong baseline.

Especially if the context is a scratchpad...

However, for more complex criteria and documents, zero-shot in-one-word methods fall short because it basically amounts to fuzzy, open-label classification. Some failure modes:

- Many attributes are too complex to be extracted in a single forward without chain-of-thought
- Attributes are often difficult to summarize in one word, especially when the space of possible words to use is itself very ambiguous (e.g. "the sequence of operations used to solve the word problem")
- Token-collision edgecases can occur, where one-word descriptions start with the same token

same:

But it does not generalize to complex criteria, which require reasoning

Also, for tasks with an obvious "nomenclature", in-one-word performance is limited
For simple documents and criteria, it's possible to extract a property of interest in a single forward pass. However, for non-trivial criteria, it's not feasible to extract and represent ... even for well-defined properties

### Finding: extensions of "in-one-word" are even more powerful

LMs are strong few-shot classifiers.
Given the appropriate context, classification-style methods demonstrate strong performance on conditional similarity evaluations.


To create a stronger baseline, we make a few adjustments.

1. We create a detailed category schema. In-one-word methods appear to implicitly define a set of classes, and we can canonicalize the output space for ambiguous criteria by explicitly passing a category schema.
2. Allow chain of thought. Sample multiple times to obtain a distribution over classes.
3. "Remap" to letters, which supports up to 26 categories. This avoids the need for one-word token collisions.


- Overall:
    - Given that LLMâ€™s have strong capabilities for zero-classification, a strong baseline is using an LM to propose a detailed taxonomy and asking the LM to score the example's affinity with each class.
    - By constructing a "logit vectr" over the classes, we can easily creates semantic invariance to irrelevant properties and focus on the requested criteria.
- Limitations
    - However, this approach remains extremely brittle
    - The largest weakness is the dependence on the taxonomy.
        - Issue: comprehensiveness
            - in one word probably wins if the condition is "what is the animal in the photo"
        - Issue: reliability
            - A possible ablation: given a criteria, generate the category schema 10 times, then run in-one-word or classification (sample 100 times and get a distribution over classes). The variance in triplet scores will be really high! (To grade, use a strong judge without any taxonomy access)
    - In general this is very hand crafted, hacky thing to do. For example, if the category schema is a bad fit, the embeddiings will contain virtually no information... and as the task gets harder, it becomes more and more difficult to create a non-ambiguous taxonomy.

Finding: extensions of "in-one-word" are not helpful for sparse matches or complex criteria

Better approaches are needed
- Overall, pseudo-classification based approaches increasingly brittle for more complex documents and criteria
- ==what tho==
