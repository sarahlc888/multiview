# Example benchmark configuration for lm_all annotation
# This shows how to use the full lm_all annotation pipeline (categories + tags + summaries)

run_name: "lm_all_example"
logging:
  level: DEBUG
  output_file: outputs/logs/benchmark_lm_all.log
seed: 42
use_cache: true

tasks:
  defaults:
    max_docs: 20
    max_triplets: 10

    # Use lm_all: LM-based triplet creation with rich annotations (categories + tags + summaries)
    # This automatically uses annotations/union_all.py for annotation
    triplet_style: "lm_all"

    # Annotation configuration
    n_schema_samples: 10          # Number of documents to sample for schema generation

    # Triplet creation strategy
    candidate_strategy: "multi"    # Combine BM25, embedding, and Jaccard similarity
    use_spurious_hard_negs: true   # Include spurious hard negatives in candidate pool
    embedding_preset: "hf_qwen3_embedding_8b"

  task_list:
    # Example 1: Math word problems - analyze arithmetic operations
    - document_set: gsm8k
      criterion: arithmetic_operations
      criterion_description: "Types of arithmetic operations used to solve the problem"

      # Schema hints - guide the LM to create better schemas
      category_schema_hint: |
        Focus on the PRIMARY operation type needed to solve the problem.
        Categories should distinguish between addition-heavy, multiplication-heavy,
        division-heavy problems, etc.

      tag_schema_hint: |
        Create binary tags for:
        - Each arithmetic operation that appears (addition, subtraction, multiplication, division)
        - Whether fractions or decimals are involved
        - Whether multi-step reasoning is required
        - Whether the problem involves word problem context

      summary_guidance_hint: |
        Focus on listing the sequence of operations needed to solve the problem.
        Be specific about what operations are applied and in what order.

      summary_format_hint: |
        Use a structured format like:
        Step 1: [operation]
        Step 2: [operation]
        ...

      # Optional: Provide an example triplet to guide the LM judge
      triplet_example:
        anchor: "Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?"
        pos: "A robe takes 2 bolts of blue fiber and half that much white fiber. How many bolts in total does it take?"
        neg: "Josh decides to try flipping a house. He buys a house for $80,000 and then puts in $50,000 in repairs. This increased the value of the house by 150%. How much profit did he make?"

    # Example 2: Crossword clues - analyze clue types
    - document_set: crossword_clues
      criterion: clue_type
      criterion_description: "The type of wordplay or technique used in the crossword clue"

      category_schema_hint: |
        Categories should distinguish between major clue types:
        - Straightforward definition clues
        - Cryptic clues with wordplay
        - Fill-in-the-blank clues
        - Trivia/knowledge-based clues

      tag_schema_hint: |
        Tag specific techniques:
        - Uses anagram
        - Uses abbreviation
        - Uses pun or homophone
        - References pop culture
        - Requires domain knowledge (science, history, etc.)

      summary_guidance_hint: |
        Describe the clue structure and any wordplay mechanisms.

      summary_format_hint: |
        Type: [clue type]
        Technique: [wordplay technique if any]
        Domain: [required knowledge domain if any]

methods_to_evaluate:
  bm25:
    - bm25
    - bm25_annotated
  embedding_models:
    - provider: openai
      model: text-embedding-3-large
  lm_judge_triplet:
    - lmjudge_triplet_plaintext_binaryhard_gemini
